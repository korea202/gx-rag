{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8052d641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>ae28101b-a42e-45b7-b24b-4ea0f1fb2d50</td>\n",
       "      <td>비뇨기계와 순환계는 혈액이 신장을 통과하면서 폐기물과 물이 제거될 때 관여하는 두 ...</td>\n",
       "      <td>비뇨기계는 신장과 요관을 통해 혈액 정화와 노폐물 제거에 기여하며, 순환계는 심장과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>eb727a4f-29c7-4d0c-b364-0e67de1776e9</td>\n",
       "      <td>로봇은 현대 산업에서 많은 역할을 수행할 수 있습니다. 그러나 로봇 사용의 중대한 ...</td>\n",
       "      <td>로봇은 산업 현장에서 인간의 위험 작업을 수행하며, 조립 과정의 정확성과 일관성 유...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>0c8c0086-c377-4201-81fa-25159e5435a7</td>\n",
       "      <td>월경은 여성의 생리주기에 따라 발생하는 현상으로, 에스트로겐과 프로게스테론 수치의 ...</td>\n",
       "      <td>월경은 여성의 생리주기와 에스트로겐·프로게스테론 변화에 의해 발생하며, 자궁 내막 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>06da6a19-ec78-404e-9640-9fc33f63c6a2</td>\n",
       "      <td>식물이 내뿜는 가스는 산소입니다. 식물은 광합성 과정을 통해 태양 에너지를 이용하여...</td>\n",
       "      <td>식물은 광합성 과정을 통해 태양 에너지와 이산화탄소를 이용해 산소를 생성하며, 이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>03c36d5e-c711-4dc2-b4db-aaeb94d86395</td>\n",
       "      <td>버퍼 오버런은 개발자들이 만든 널리 퍼져 있는 앱의 코딩 오류로써, 공격자가 시스템...</td>\n",
       "      <td>버퍼 오버런은 개발자 코딩 오류로 발생하는 보안 취약점으로, 메모리 버퍼 초과 접근...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     docid  \\\n",
       "4267  ae28101b-a42e-45b7-b24b-4ea0f1fb2d50   \n",
       "4268  eb727a4f-29c7-4d0c-b364-0e67de1776e9   \n",
       "4269  0c8c0086-c377-4201-81fa-25159e5435a7   \n",
       "4270  06da6a19-ec78-404e-9640-9fc33f63c6a2   \n",
       "4271  03c36d5e-c711-4dc2-b4db-aaeb94d86395   \n",
       "\n",
       "                                                content  \\\n",
       "4267  비뇨기계와 순환계는 혈액이 신장을 통과하면서 폐기물과 물이 제거될 때 관여하는 두 ...   \n",
       "4268  로봇은 현대 산업에서 많은 역할을 수행할 수 있습니다. 그러나 로봇 사용의 중대한 ...   \n",
       "4269  월경은 여성의 생리주기에 따라 발생하는 현상으로, 에스트로겐과 프로게스테론 수치의 ...   \n",
       "4270  식물이 내뿜는 가스는 산소입니다. 식물은 광합성 과정을 통해 태양 에너지를 이용하여...   \n",
       "4271  버퍼 오버런은 개발자들이 만든 널리 퍼져 있는 앱의 코딩 오류로써, 공격자가 시스템...   \n",
       "\n",
       "                                                summary  \n",
       "4267  비뇨기계는 신장과 요관을 통해 혈액 정화와 노폐물 제거에 기여하며, 순환계는 심장과...  \n",
       "4268  로봇은 산업 현장에서 인간의 위험 작업을 수행하며, 조립 과정의 정확성과 일관성 유...  \n",
       "4269  월경은 여성의 생리주기와 에스트로겐·프로게스테론 변화에 의해 발생하며, 자궁 내막 ...  \n",
       "4270  식물은 광합성 과정을 통해 태양 에너지와 이산화탄소를 이용해 산소를 생성하며, 이 ...  \n",
       "4271  버퍼 오버런은 개발자 코딩 오류로 발생하는 보안 취약점으로, 메모리 버퍼 초과 접근...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 로컬 JSON 파일 읽기\n",
    "df = pd.read_csv(\"./data/summary_two.csv\")\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf4af9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4272 entries, 0 to 4271\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   docid    4272 non-null   object\n",
      " 1   content  4272 non-null   object\n",
      " 2   summary  4272 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 100.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af36c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "class ScienceRAG:\n",
    "    def __init__(self):\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "                                    model_name=\"BAAI/bge-m3\",\n",
    "                                    model_kwargs={\"device\": \"cuda\"} ,\n",
    "                                    encode_kwargs={\"normalize_embeddings\": True})\n",
    "        self.vectorstore = FAISS.from_texts([\"초기화용 더미 텍스트\"], self.embeddings)\n",
    "        \"\"\"  # 임베딩 차원 계산\n",
    "        dimension = len(self.embeddings.embed_query(\"test\"))\n",
    "    \n",
    "        # 코사인 유사도를 위한 IndexFlatIP 생성\n",
    "        index = faiss.IndexFlatIP(dimension)\n",
    "    \n",
    "        # 빈 FAISS 벡터 스토어 생성\n",
    "        self.vectorstore = FAISS(\n",
    "            embedding_function=self.embeddings,\n",
    "            index=index,\n",
    "            docstore=InMemoryDocstore(),\n",
    "            index_to_docstore_id={},\n",
    "            normalize_L2=True  # 벡터 정규화로 코사인 유사도 구현\n",
    "        ) \"\"\"\n",
    "\n",
    "        # 요약 체인\n",
    "        #self.summary_chain = science_summary_chain\n",
    "        #self.summary_chain = two_step_chain\n",
    "    \n",
    "    def add_documents(self, df):\n",
    "        \"\"\"문서를 요약하여 벡터DB에 저장\"\"\"\n",
    "        \n",
    "        texts = df['summary'].tolist()\n",
    "        metadatas = [\n",
    "            {\n",
    "                'docid': row['docid'],\n",
    "                'content': row['content']\n",
    "            } \n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "        ids = df['docid'].tolist()\n",
    "\n",
    "\n",
    "        # 2. 검색용 요약을 벡터DB에 저장\n",
    "        self.vectorstore.add_texts(\n",
    "            texts,\n",
    "            metadatas=metadatas,\n",
    "            ids = ids\n",
    "        )\n",
    "        \n",
    "       \n",
    "    def search(self, query: str, k: int = 3):\n",
    "        \"\"\"요약된 내용으로 검색\"\"\"\n",
    "        results = self.vectorstore.similarity_search(query, k=k)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a10e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시\n",
    "science_rag = ScienceRAG()\n",
    "\n",
    "science_rag.add_documents(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2a8f5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='70d104b2-8d74-4799-a09d-5a4c8dd577c0', metadata={'docid': '70d104b2-8d74-4799-a09d-5a4c8dd577c0', 'content': '언어 {ww | w in (0 + 1)*}는 특정한 조건을 만족하는 문자열의 집합입니다. 이 언어는 일부 튜링 기계에 의해 허용되지만, 푸시다운 오토마톤에 의해서는 허용되지 않습니다. 튜링 기계는 다양한 계산 작업을 수행할 수 있는 추상적인 컴퓨팅 장치입니다. 그러나 푸시다운 오토마톤은 스택을 사용하여 제한된 형태의 계산 작업만을 수행할 수 있습니다. 따라서 언어 {ww | w in (0 + 1)*}는 튜링 기계에 의해 허용되지만, 푸시다운 오토마톤에 의해서는 허용되지 않습니다. 이러한 언어의 특성은 컴퓨터 과학 분야에서 중요한 개념으로 다루어지고 있습니다.'}, page_content='언어 {ww | w in (0 + 1)*}는 튜링 기계에 의해 허용되지만 푸시다운 오토마톤에 의해 허용되지 않으며, 이는 스택 기반 계산의 제한성과 튜링 기계의 계산 능력 차이를 보여주는 핵심 사례이다.'),\n",
       "  np.float32(0.9753531)),\n",
       " (Document(id='651c1b65-b620-4abf-bfcd-7e6753e64142', metadata={'docid': '651c1b65-b620-4abf-bfcd-7e6753e64142', 'content': '지구는 자전축을 중심으로 하루에 한 번 자전합니다. 이는 지구의 자전 속도와 자전축의 기울기에 의해 결정됩니다. 자전축은 지구의 지평선과 약 23.5도의 각도로 기울어져 있으며, 이로 인해 지구는 하루에 한 번 자전합니다. 이 자전은 지구의 낮과 밤의 변화를 만들어내고, 시간의 흐름을 결정하는 중요한 역할을 합니다. 따라서, 지구는 매일 한 번 자전함으로써 우리에게 일상 생활에서 익숙한 낮과 밤의 변화를 제공합니다.'}, page_content='지구는 자전축을 중심으로 자전속도와 기울기로 결정되는 자전을 하며, 자전축이 지평선과 23.5도 기울어져 하루에 한 번 자전함으로써 낮과 밤의 변화를 만들고 시간의 흐름을 결정한다.'),\n",
       "  np.float32(1.0009336)),\n",
       " (Document(id='b12ab9a7-3d8d-438c-bb06-a0ec7e514344', metadata={'docid': 'b12ab9a7-3d8d-438c-bb06-a0ec7e514344', 'content': '차량의 질량이 1500kg이며, 이동 시 초당 2m/s 씩 속도를 증가시킵니다. 이에 따라 차량에 작용하는 알짜 힘을 계산해보겠습니다. 알짜 힘은 질량과 가속도의 곱으로 계산됩니다. 따라서, 차량의 질량인 1500kg에 가속도인 2m/s^2를 곱하면 알짜 힘은 3000 N입니다. 따라서, 이 차량에 작용하는 알짜 힘은 3000 N입니다.'}, page_content='차량의 질량 1500kg과 가속도 2m/s²이 주어졌으며, 질량과 가속도의 곱인 알짜 힘은 3000N으로 계산된다.'),\n",
       "  np.float32(1.003975))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"오토마톤의 특징에 대해 알려줘.\"\n",
    "docs = science_rag.vectorstore.similarity_search_with_score(query, k=3)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"alibayram/Qwen3-30B-A3B-Instruct-2507\")\n",
    "\n",
    "# 프롬프트 \n",
    "convertFormat = \"\"\"\n",
    "당신은 문자열 포맷 마이그레이션 전문가 입니다. <message> 에서 content 내용만 문자열로 출력합니다. 만일 content가 여러개가 있으면 전체적인 문맥을 파악하여 질문을 만들어서 출력합니다.\n",
    "\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "[example]\n",
    "\n",
    "    <message>{\"role\": \"user\", \"content\": \"피를 맑게 하고 몸 속의 노폐물을 없애는 역할을 하는 기관은?\"}</message> \n",
    "    output:피를 맑게 하고 몸 속의 노폐물을 없애는 역할을 하는 기관은? \n",
    "\n",
    "    <message>{\"role\": \"user\", \"content\": \"이란 콘트라 사건이 뭐야\"}, {\"role\": \"assistant\", \"content\": \"이란-콘트라 사건은 로널드 레이건 집권기인 1986년에 레이건 행정부와 CIA가 적성국이었던 이란에게 무기를 몰래 수출한 대금으로 니카라과의 우익 성향 반군 콘트라를 지원하면서 동시에 반군으로부터 마약을 사들인 후 미국에 판매하다가 발각되어 큰 파장을 일으킨 사건입니다.\"}, {\"role\": \"user\", \"content\": \"이 사건이 미국 정치에 미친 영향은?\"}</message>\n",
    "    output:1986년에 발생한 이란 콘트라 사건이 미국 정치에 미친 영향은? \n",
    "\n",
    "\n",
    "output:\n",
    "[Your output here - NOTHING ELSE]\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 객체 생성\n",
    "convertFormat_prompt = PromptTemplate(\n",
    "    input_variables=[\"message\"],\n",
    "    template=convertFormat\n",
    ")\n",
    "\n",
    "# 출력 파서 (문자열)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL 체인 구성\n",
    "convertFormat_chain = (\n",
    "    convertFormat_prompt \n",
    "    | llm \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "# 프롬프트 \n",
    "selectYn = \"\"\"\n",
    "당신은 과학 상식 전문가 입니다. 만약 <message> 가 과학 상식과 관련된 질문이라면  Y 아니라면 N으로 답해주세요.\n",
    "\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "당신은 반드시 Y 뜨는 N으로 답해야 합니다.\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 객체 생성\n",
    "selectYn_prompt = PromptTemplate(\n",
    "    input_variables=[\"message\"],\n",
    "    template=selectYn\n",
    ")\n",
    "\n",
    "# 출력 파서 (문자열)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL 체인 구성\n",
    "selectYn_chain = (\n",
    "    selectYn_prompt \n",
    "    | llm \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "# 프롬프트 \n",
    "answer = \"\"\"\n",
    "당신은 과학 상식 전문가 입니다. <message> 의 질문에 대해서 주어진 <reference> 정보를 활용하여 간결하게 답변을 생성합니다.\n",
    "\n",
    "    - 주어진 검색 결과 정보로 대답할 수 없는 경우는 정보가 부족해서 답을 할 수 없다고 대답합니다.\n",
    "    - 한국어로 답변을 생성합니다..\n",
    "\n",
    "<message>\n",
    "{message}\n",
    "</message>\n",
    "\n",
    "<reference>\n",
    "{reference}\n",
    "</reference>\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 객체 생성\n",
    "answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"message\"],\n",
    "    template=answer\n",
    ")\n",
    "\n",
    "# 출력 파서 (문자열)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL 체인 구성\n",
    "answer_chain = (\n",
    "    answer_prompt \n",
    "    | llm \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(message):\n",
    "\n",
    "    docs = science_rag.vectorstore.similarity_search_with_relevance_scores(query, k=3)\n",
    "    filtered_docs = [(doc, score) for doc, score in docs if score <= 0.8] \n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# LLM과 검색엔진을 활용한 RAG 구현\n",
    "def answer_question(messages):\n",
    "    # 함수 출력 초기화\n",
    "    response = {\"standalone_query\": \"standalone_query\", \"topk\": [], \"references\": [], \"answer\": \"\"}\n",
    "\n",
    "    message = convertFormat_chain.invoke({\"message\": messages})\n",
    "    result = selectYn_chain.invoke({\"document\": message})\n",
    "\n",
    "    context = {\"message\":message}\n",
    "\n",
    "\n",
    "    if result == \"Y\":\n",
    "        context[\"reference\"], response[\"topk\"], response[\"references\"] = query_db(message)\n",
    "    else:\n",
    "        context[\"reference\"] = \"\"\n",
    "        response[\"topk\"] = []\n",
    "        response[\"references\"] = []\n",
    "    \n",
    "    response[\"answer\"] = answer_chain.invoke(context)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" if result.choices[0].message.tool_calls:\n",
    "        tool_call = result.choices[0].message.tool_calls[0]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        standalone_query = function_args.get(\"standalone_query\")\n",
    "\n",
    "        # Baseline으로는 sparse_retrieve만 사용하여 검색 결과 추출\n",
    "        search_result = sparse_retrieve(standalone_query, 3)\n",
    "\n",
    "        response[\"standalone_query\"] = standalone_query\n",
    "        retrieved_context = []\n",
    "        for i,rst in enumerate(search_result['hits']['hits']):\n",
    "            retrieved_context.append(rst[\"_source\"][\"content\"])\n",
    "            response[\"topk\"].append(rst[\"_source\"][\"docid\"])\n",
    "            response[\"references\"].append({\"score\": rst[\"_score\"], \"content\": rst[\"_source\"][\"content\"]})\n",
    "\n",
    "        content = json.dumps(retrieved_context)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "        msg = [{\"role\": \"system\", \"content\": persona_qa}] + messages\n",
    "        try:\n",
    "            qaresult = client.chat.completions.create(\n",
    "                    model=llm_model,\n",
    "                    messages=msg,\n",
    "                    temperature=0,\n",
    "                    seed=1,\n",
    "                    timeout=30\n",
    "                )\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return response\n",
    "        response[\"answer\"] = qaresult.choices[0].message.content\n",
    "\n",
    "    # 검색이 필요하지 않은 경우 바로 답변 생성\n",
    "    else:\n",
    "        response[\"answer\"] = result.choices[0].message.content \"\"\"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def eval_rag(eval_filename, output_filename):\n",
    "    with open(eval_filename) as f, open(output_filename, \"w\") as of:\n",
    "        idx = 0\n",
    "        for line in f:\n",
    "            j = json.loads(line)\n",
    "            print(f'Test {idx}\\nQuestion: {j[\"msg\"]}')\n",
    "            response = answer_question(j[\"msg\"])\n",
    "            print(f'Answer: {response[\"answer\"]}\\n')\n",
    "\n",
    "            # 대회 score 계산은 topk 정보를 사용, answer 정보는 LLM을 통한 자동평가시 활용\n",
    "            output = {\"eval_id\": j[\"eval_id\"], \"standalone_query\": response[\"standalone_query\"], \"topk\": response[\"topk\"], \"answer\": response[\"answer\"], \"references\": response[\"references\"]}\n",
    "            of.write(f'{json.dumps(output, ensure_ascii=False)}\\n')\n",
    "            idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 데이터에 대해서 결과 생성 - 파일 포맷은 jsonl이지만 파일명은 csv 사용\n",
    "eval_rag(\"./data/eval.jsonl\", \"sample_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gx-rag (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
