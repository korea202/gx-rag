{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9217f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문서 로드\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('/data/ephemeral/home/work/python/gx-rag/src/apps/persona/data/source', glob=\"*\", show_progress=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba191048",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(docs[0])\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문서 의미 있게 자르기 (1, 2, 3,4 ...장 별로)\n",
    "\n",
    "import re\n",
    "from langchain.schema import Document\n",
    "\n",
    "pattern = r'(?=\\d+\\.\\s)'  # \n",
    "#pattern = r'(?=^\\d{1,2}\\.\\s)'  # Positive Lookahead 사용\n",
    "#pattern = r'(?=[0-9]{1,2}\\.\\s)'    # ASCII 2자리\n",
    "#pattern = r'(?=[1-9]\\d?\\.\\s)'  # 1-9 또는 10-99\n",
    "\n",
    "all_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "chunks = re.split(pattern, all_text, flags=re.MULTILINE)\n",
    "# 무효한 리스트 삭제하기\n",
    "valid_chunks = [chunk.strip() for chunk in chunks if len(chunk.strip()) > 100 and not chunk.strip().isdigit()]\n",
    "len(valid_chunks)\n",
    "\n",
    "valid_docs = [Document(page_content=chunk, metadata={'level': 'parent'}) for chunk in valid_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-1  내용 확인(test)\n",
    "for doc in valid_docs:\n",
    "    print(\"*\"*50)\n",
    "    print(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2 사이즈 확인(test)\n",
    "def get_chunk_size_by_words(docs):\n",
    "    \n",
    "    for doc in docs:\n",
    "        print(len(doc.split()))\n",
    "\n",
    "get_chunk_size_by_words(valid_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 디비에 저장\n",
    "\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import LocalFileStore, create_kv_docstore\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "import torch\n",
    "\n",
    "embed_model=HuggingFaceEmbeddings(\n",
    "                                    model_name=\"BAAI/bge-m3\",\n",
    "                                    model_kwargs={\"device\": \"cuda\"} ,\n",
    "                                    encode_kwargs={\"normalize_embeddings\": True})\n",
    "\n",
    "\n",
    "\"\"\" # HuggingFaceEmbeddings 인스턴스 생성\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-8B\",\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\"  # GPU 사용 (CPU는 \"cpu\")\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        \"normalize_embeddings\": True  # 임베딩 정규화\n",
    "    }\n",
    ") \"\"\"\n",
    "\n",
    "# 1. 컴포넌트 설정\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=500)  # 작은 청크\n",
    "#vectorstore = Chroma(embedding_function=embeddings)  # 벡터 저장소\n",
    "\n",
    "# 빈 벡터스토어 생성\n",
    "vectorstore = FAISS.from_texts(\n",
    "    texts=[\"초기화\"],  # 더미 텍스트\n",
    "    embedding=embed_model\n",
    ")\n",
    "\n",
    "#store = InMemoryStore()\n",
    "# doc스토어 시스템에 영구 저장\n",
    "fs = LocalFileStore(root_path=\"/data/ephemeral/home/work/python/gx-rag/src/apps/persona/data/store\")\n",
    "store = create_kv_docstore(fs) \n",
    "\n",
    "# 2. ParentDocumentRetriever 생성\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,    # 청크 저장 (검색용)\n",
    "    docstore=store,            # 원본 저장 (반환용)  \n",
    "    child_splitter=child_splitter,  # 분할 방법\n",
    "    search_kwargs={\"k\": 1} \n",
    ")\n",
    "\n",
    "# 3. 문서 추가\n",
    "retriever.add_documents(valid_docs)\n",
    "\n",
    "# 벡터스토어 저장\n",
    "vectorstore.save_local('/data/ephemeral/home/work/python/gx-rag/src/apps/persona/data/faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb140d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "result= retriever.get_relevant_documents('은성호 사건을 해결할수 있었던 힌트는?')\n",
    "print(result[0].page_content)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.  요약 쿼리 템플릿\n",
    "\n",
    "template = \"\"\"\n",
    "아래 <context> 내용을 요약해서 원본 크기의 30%정도의 크기로 만들어줘. \n",
    "<context> 에 있는 내용만 이야기해줘.\n",
    "양식의 규격을 준수해줘.  \n",
    "\n",
    "[example]\n",
    "\n",
    "<context>\n",
    "    나는 1878년 런던 대학에서 의학 박사 학위를 받고 군의관이 되기 위해 필요한 \n",
    "자격을 따기 위해 네틀리 육군 병원에 들어갔다. 그곳에서 규정된 교육을 끝내고 \n",
    "노섬벌랜드 연대 소속 군의관으로 임명되었다.\n",
    "그 무렵 이 연대는 인도에 주둔하고 있었는데, 내가 현지에 도착하기도 전에 제2\n",
    "차 아프가니스탄 전쟁이 일어났다. 나는 봄베이에 상륙해서야 나의 연대가 적진 \n",
    "깊숙이로 공격해 들어간 것을 알았다. 그래서 길을 재촉하여 그 뒤를 쫓아가 ㄴ\n",
    "무사히 연대를 만나 새로운 임무에 종사하게 되었던 것이다.\n",
    "이 전쟁에서 나는 연거푸 재난과 마주쳐야 했다. 마이완드에서 격전에 참가했다\n",
    "가 어깨에 탄환을 맞아 뼈가 으스러지고 동맥까지 다치게 되었던 것이다.\n",
    "다행히 전령을 맡고 있던 부하 머레이가 충직하고 용감한 사람이어서, 나를 말 \n",
    "위에 짐짝처럼 싣고 무사히 아군의 진지까지 데리고 돌아왔으니 망정이지, 만일 \n",
    "그가 없었다면 나는 잔인한 적의 수중에 사로잡혔을 것이다.\n",
    "나는 후방 병원으로 보내졌다. 그 곳에서 어느 정도 건강이 회복되어 병원 안을 \n",
    "걸어다니기도 하고, 베란다에 나가 일광욕도 할 만큼 회복되었는데, 운수 사납게\n",
    "도 이번에는 장티푸스에 걸리고 말았다.\n",
    "</context>\n",
    "\n",
    "<summary>\n",
    "    나는 1878년 런던 대학에서 의학 박사 학위를 받고 네틀리 육군 병원에서 군의관 교육을 받은 후, 노섬벌랜드 연대 소속 군의관으로 임명되었다.\n",
    "제2차 아프가니스탄 전쟁이 발발하여 인도로 파견된 나는 봄베이에 도착해서야 연대가 이미 전선으로 떠났음을 알고 급히 뒤를 쫓아 연대와 합류했다.\n",
    "전쟁 중 마이완드 격전에서 어깨에 탄환을 맞아 뼈가 으스러지고 동맥까지 다쳤다. 다행히 부하 머레이가 나를 구해 후방 병원으로 이송되었고, 어느 정도 회복되었으나 이번엔 장티푸스에 걸렸다.\n",
    "</summary>\n",
    "\n",
    "\n",
    "[Generate]\n",
    "\n",
    "<context>\n",
    "    {context}\n",
    "</context>\n",
    "\n",
    "<summary>\n",
    "    [Your summary here - NOTHING ELSE]\n",
    "</summary>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.  요약쿼리 테스트\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "#llm = ChatOllama(model=\"phi4:latest\")\n",
    "llm = ChatOllama(model=\"alibayram/Qwen3-30B-A3B-Instruct-2507\")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "holmes_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "# 체인 실행 전에 프롬프트 미리 확인\n",
    "\"\"\" formatted_prompt = prompt.format(context=valid_docs[2].page_content)\n",
    "print(\"=== 실제 전달될 프롬프트 ===\")\n",
    "print(formatted_prompt)\n",
    "print(\"=\" * 50)  \"\"\"\n",
    "\n",
    "\n",
    "result = holmes_chain.invoke({'context': valid_docs[2].page_content})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gx-rag (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
